{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Full Neural Networks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/Z6CNqhFxNePPpfLjzjy9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/123-code/Neural-Networks-from-scratch/blob/main/Full_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBeWQv78cvxr",
        "outputId": "9f2ffdf5-8e7d-4620-9379-13d9a551133a"
      },
      "source": [
        "import numpy as np\n",
        "!pip install nnfs\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnfs\n",
            "  Downloading nnfs-0.5.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nnfs) (1.19.5)\n",
            "Installing collected packages: nnfs\n",
            "Successfully installed nnfs-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdhWHvN6c90G",
        "outputId": "fb680f03-94ff-4325-c0f2-cd11e2e056f1"
      },
      "source": [
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "nnfs.init()\n",
        "\n",
        "\n",
        "class Layer:\n",
        "  def __init__(self,inputs,nneurons):\n",
        "    self.weights = 0.10 * np.random.randn(inputs,nneurons)\n",
        "    self.bias = np.zeros((1,nneurons))\n",
        "\n",
        "  def forward(self,inputs):\n",
        "      self.output = np.dot(inputs,self.weights) + self.bias\n",
        "     \n",
        "\n",
        "\n",
        "class RELU_A:\n",
        "  def forward(self,inputs):\n",
        "\n",
        "    self.output = np.maximum(0,inputs)\n",
        "\n",
        "\n",
        "class Softmax:\n",
        "  def forward(self,inputs):\n",
        "    exp_values = np.exp(inputs - np.max(inputs,axis=1,keepdims=True))\n",
        "    probabilities = exp_values/np.sum(exp_values,axis=1,keepdims=True)\n",
        "    self.output = probabilities\n",
        "\n",
        "class Loss:\n",
        "  # output from the model and target values.\n",
        "  def calculate(self,output,y):\n",
        "    sample_losses = self.forward(output,y)\n",
        "    data_loss = np.mean(sample_losses)\n",
        "    return data_loss\n",
        "\n",
        "class categoricalcrossentropy(Loss):\n",
        "  def forward(self,y_pred,y_true):\n",
        "    samples = len(y_pred)\n",
        "    y_pred_clipped = np.clip(y_pred,1e-7,1-1e-7)\n",
        "\n",
        "    if len(y_true.shape)==1:\n",
        "      correct_conf = y_pred_clipped[range(samples),y_true]\n",
        "    elif len(y_true.shape)==2:\n",
        "      correct_conf = np.sum(y_pred_clipped*y_true,axis=1)\n",
        "    \n",
        "    negative_log_likelihoods = np.log(correct_conf)\n",
        "    return negative_log_likelihoods\n",
        "\n",
        "\n",
        "\n",
        "X,y = spiral_data(samples=100,classes=3)\n",
        "dense1 = Layer(2,3)\n",
        "activation1 = RELU_A()\n",
        "\n",
        "dense2 = Layer(3,3)\n",
        "activation2 = Softmax()\n",
        "dense1.forward(X)\n",
        "activation1.forward(dense1.output)\n",
        "dense2.forward(activation1.output)\n",
        "activation2.forward(dense2.output)\n",
        "print(activation2.output[:5])\n",
        "Loss = categoricalcrossentropy()\n",
        "loss = Loss.calculate(activation2.output,y)\n",
        "print(\"Loss:\",loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.33333334 0.33333334 0.33333334]\n",
            " [0.33331734 0.3333183  0.33336434]\n",
            " [0.3332888  0.33329153 0.33341965]\n",
            " [0.33325943 0.33326396 0.33347666]\n",
            " [0.33323312 0.33323926 0.33352762]]\n",
            "Loss: -1.098445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFMRKLLzaIVj"
      },
      "source": [
        "Neural Network 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCLrh13-aKhp",
        "outputId": "35cbc5cd-5815-463c-94db-c4876ca76bca"
      },
      "source": [
        "data = [[2,5,8,9],[6,8,3,1],[7,9,4,5],[6,4,2,1]]\n",
        "#np.random.seed(0)\n",
        "# setting initial weights and biases. \n",
        "class Layer1:\n",
        "  def __init__(self,n_inputs,n_neurons):\n",
        "    self.weights = 0.10 * np.random.randn(n_inputs,n_neurons)\n",
        "    self.biases = np.zeros((1,n_neurons))\n",
        "\n",
        "  def Forward_pass(self,inputs):\n",
        "    self.output = np.dot(inputs,self.weights) + self.biases\n",
        "# Values printed in output are a matrix of each neurons dot product result. \n",
        "\n",
        "class RELU:\n",
        "  def forward(self,inputs):\n",
        "\n",
        "    self.output = np.maximum(0,inputs)\n",
        "  \n",
        "\n",
        "L1 = Layer1(4,3)\n",
        "L1.Forward_pass(data)\n",
        "print(L1.output)\n",
        "activation_1 = RELU()\n",
        "activation_1.forward(L1.output)\n",
        "print(activation_1.output[:5])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.48369895 1.06012667 2.91633185]\n",
            " [1.78269892 0.50147318 3.0249836 ]\n",
            " [1.97679322 0.88927948 3.86635385]\n",
            " [1.4470814  0.76571782 2.16623242]]\n",
            "[[0.48369895 1.06012667 2.91633185]\n",
            " [1.78269892 0.50147318 3.0249836 ]\n",
            " [1.97679322 0.88927948 3.86635385]\n",
            " [1.4470814  0.76571782 2.16623242]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uitg8vBbAm_v"
      },
      "source": [
        "softmax_outputs = np.array([0.7,0.1,0.2],\n",
        "                           [0.1,0.5,0.4],\n",
        "                           [0.02,0.9,0.08])\n",
        "\n",
        "class_targets = [0,1,1]\n",
        "print(softmax_outputs[0,1,2],class_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwV-QyNKE90J"
      },
      "source": [
        "Full NN 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-_jGd7RFAeN"
      },
      "source": [
        "def sigmoid(x):\n",
        "  sigmoid = (1/(1+np.exp(-x)))\n",
        "  return sigmoid\n",
        "\n",
        "# randomly initializing weights.\n",
        "def init_W(inp_size,hidd_size):\n",
        "  weights = {}\n",
        "  weights['W1'] = np.random.randn(inp_size,hidd_size)\n",
        "  weights['B1'] = np.random.randn(1,hidd_size)\n",
        "  weights['W2'] = np.random.randn(inp_size,hidd_size)\n",
        "  weights['B2'] = np.random.randn(1,hidd_size)\n",
        "  return weights\n",
        "\n",
        "def Forward_Loss(X,y,weights):\n",
        "  W_sum = np.dot(X,weights['W1'])\n",
        "  output = W_sum + weights['B1']\n",
        "  Activated1 = np.dot(W_sum,output)\n",
        "\n",
        "  W_sum2 = np.dot(Activated1,weights['W2'])\n",
        "  output2 = W_sum + weights['B1']\n",
        "\n",
        "  loss = np.mean((y-output2)**2)\n",
        "\n",
        "# saving forward pass data.\n",
        "  forward_info = {}\n",
        "  forward_info['W_sum1'] = W_sum\n",
        "  forward_info['output1'] = output\n",
        "  forward_info['Sigm1'] = Activated1\n",
        "  forward_info['Wsum2'] = W_sum2\n",
        "  forward_info['output2'] = output2\n",
        "  forward_info['X'] = X\n",
        "  forward_info['y'] = y\n",
        "\n",
        "  return forward_info,loss\n",
        "\n",
        "def Calc_gradients():\n",
        "  pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    }
  ]
}