{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4zcpU8RPAY/P99UoO178C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/123-code/Neural-Networks-from-scratch/blob/main/MyNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdYWNhCRiuOq",
        "outputId": "c1897c1e-42b1-41bf-c3b0-f186703c0c14"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "X =    [[1, 2, 3, 2.5],\n",
        "     [2.0, 5.0, -1.0, 2.0],\n",
        "     [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "y = np.ones((3,3))\n",
        "\n",
        "\n",
        "class Layer:\n",
        "  def __init__ (self,inputs,nneurons):\n",
        "    self.weights = 0.10 * np.random.randn(inputs,nneurons)\n",
        "    self.bias = np.zeros((1,nneurons))\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    \n",
        "    output = np.dot(inputs,self.weights) + self.bias\n",
        "    return output\n",
        "\n",
        "class RELU:\n",
        "  def __init__(self,inputs):\n",
        "    self.output = np.maximum(0,inputs)\n",
        "  def calculate(self):\n",
        "    return self.output\n",
        "\n",
        "class Loss:\n",
        "  def __init__(self,output,y):\n",
        "    self.loss = (output - y)**2\n",
        "    self.mse = np.mean(self.loss)\n",
        "  def calculate(self):\n",
        "\n",
        "    return self.mse\n",
        "\n",
        "class Gradients:\n",
        "  def __init__(self,inputs,y):\n",
        "    n = inputs.shape[0]\n",
        "    self.output = 2*(inputs-y)/n\n",
        "  def calculate(self):\n",
        "    return self.output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "layer1 = Layer(4,3)\n",
        "pred = layer1.forward(X)\n",
        "print(f'Predicted:  {pred}\\n')\n",
        "\n",
        "activation1 = RELU(pred)\n",
        "activation1 = activation1.calculate()\n",
        "\n",
        "print(f'Actual:{y}\\n')\n",
        "\n",
        "\n",
        "print(f'Activation:{activation1}\\n')\n",
        "\n",
        "loss = Loss(y,activation1)\n",
        "loss = loss.calculate()\n",
        "print(f'Loss:{loss}\\n')\n",
        "\n",
        "\n",
        "gradients = Gradients(pred,y)\n",
        "gradients = gradients.calculate()\n",
        "print(f'Gradients:{gradients}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted:  [[-0.24596451 -0.44296989  0.10187329]\n",
            " [-0.38611024 -0.37879149 -0.17926033]\n",
            " [ 0.10608344 -0.6721945   0.44633901]]\n",
            "\n",
            "Actual:[[1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]]\n",
            "\n",
            "Activation:[[0.         0.         0.10187329]\n",
            " [0.         0.         0.        ]\n",
            " [0.10608344 0.         0.44633901]]\n",
            "\n",
            "Loss:0.8791398766872176\n",
            "\n",
            "Gradients:[[-0.83064301 -0.96197992 -0.59875114]\n",
            " [-0.92407349 -0.91919433 -0.78617355]\n",
            " [-0.59594438 -1.11479633 -0.36910732]]\n"
          ]
        }
      ]
    }
  ]
}