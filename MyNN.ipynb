{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOTwhm2jkOrUCUOpfp+TYK1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/123-code/Neural-Networks-from-scratch/blob/main/MyNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdYWNhCRiuOq"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "X =    [[1, 2, 3, 2.5],\n",
        "     [2.0, 5.0, -1.0, 2.0],\n",
        "     [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "y = np.ones((3,3))\n",
        "\n",
        "\n",
        "class Layer:\n",
        "  def __init__ (self,inputs,nneurons):\n",
        "    self.weights = 0.10 * np.random.randn(inputs,nneurons)\n",
        "    self.bias = np.zeros((1,nneurons))\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    \n",
        "    output = np.dot(inputs,self.weights) + self.bias\n",
        "    return output\n",
        "\n",
        "  def backward(self,gradients,lr):\n",
        "    for i in range(len(self.weights)):\n",
        "      self.weights[i] = (self.weights - gradients) * lr\n",
        "      \n",
        "\n",
        "class RELU:\n",
        "  def __init__(self,inputs):\n",
        "    self.output = np.maximum(0,inputs)\n",
        "  def calculate(self):\n",
        "    return self.output\n",
        "\n",
        "class Loss:\n",
        "  def __init__(self,output,y):\n",
        "    self.loss = (output - y)**2\n",
        "    self.mse = np.mean(self.loss)\n",
        "  def calculate(self):\n",
        "\n",
        "    return self.mse\n",
        "\n",
        "class Gradients:\n",
        "  def __init__(self,inputs,y):\n",
        "    n = inputs.shape[0]\n",
        "    self.output = 2*(inputs-y)/n\n",
        "  def calculate(self):\n",
        "    return self.output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "layer1 = Layer(4,3)\n",
        "\n",
        "\n",
        "# training\n",
        "n_epochs = 5\n",
        "for i in range(n_epochs):\n",
        "\n",
        "  pred = layer1.forward(X)\n",
        "\n",
        "  print(f'Predicted:  {pred}\\n')\n",
        "\n",
        "  activation1 = RELU(pred)\n",
        "  activation1 = activation1.calculate()\n",
        "\n",
        "  print(f'Actual:{y}\\n')\n",
        "\n",
        "\n",
        "  print(f'Activation:{activation1}\\n')\n",
        "\n",
        "  loss = Loss(y,activation1)\n",
        "  loss = loss.calculate()\n",
        "  print(f'Loss:{loss}\\n')\n",
        "\n",
        "\n",
        "  gradients = Gradients(pred,y)\n",
        "  gradients = gradients.calculate()\n",
        "  print(f'Gradients:{gradients}\\n')\n",
        "\n",
        "  for weight in layer1.weights:\n",
        "\n",
        "    layer1.weights = Layer.weights - 0.5*(gradients)\n",
        "    print(f'Layer Weights:{layer1.weights}\\n')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}